{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check correct import\n",
    "def test_util():\n",
    "    return \"Import complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#description of sklearn datasets\n",
    "def descRaw(ds):\n",
    "    print(ds['DESCR'])\n",
    "    for key,value in ds.items():\n",
    "        print(key,'\\n', value,'\\n')    \n",
    "    #print target classes\n",
    "    print('data.shape\\t',ds['data'].shape,'\\ntarget.shape \\t',ds['target'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert sklearn dataset into pandas dataframe\n",
    "def pandasConverter(ds):\n",
    "    features=pd.DataFrame(data=ds['data'],columns=ds['feature_names'])\n",
    "    df=features\n",
    "    df['target']=ds['target']\n",
    "    df['class']=df['target'].map(lambda ind: ds['target_names'][ind])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print correlation matrix of the relative dataframe\n",
    "def corrMatrix(df,tit):\n",
    "    corr = df[df.columns].corr()\n",
    "    f, ax = plt.subplots(figsize=(15, 10))\n",
    "    if tit == \"iris\":\n",
    "        ax.set_title('IRIS CORRELATION MATRIX')\n",
    "    else:\n",
    "        ax.set_title('WINE CORRELATION MATRIX')\n",
    "    ax=sns.heatmap(corr, cmap=\"YlGnBu\", annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a new dataframe with only the 2 kbest features\n",
    "def KbestRaw(ds,df):\n",
    "    # Create features and target\n",
    "    X = ds.data\n",
    "    y = ds.target\n",
    "    # Select two features with highest chi-squared statistics\n",
    "    chi2_selector = SelectKBest(chi2, k=2)\n",
    "    chi2_selector.fit(X, y)\n",
    "\n",
    "    #print chi2 scores\n",
    "    chi2_scores = pd.DataFrame(list(zip(ds.feature_names, chi2_selector.scores_, chi2_selector.pvalues_)), columns=['ftr', 'score', 'pval'])\n",
    "    print(chi2_scores)\n",
    "\n",
    "    #print kbest features names\n",
    "    kbest = np.asarray(ds.feature_names)[chi2_selector.get_support()]\n",
    "    print(\"kbest: \",kbest)\n",
    "    #create new df with kbest features\n",
    "    new_df=df[kbest]\n",
    "    new_df['target']=ds['target']\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition of MDC class\n",
    "class MDC():\n",
    "    def init(self):\n",
    "        self.class_list = {}\n",
    "        self.centroids = {}\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.class_list = np.unique(y, axis=0)\n",
    "        self.centroids = np.zeros((len(self.class_list), X.shape[1])) # each row is a centroid\n",
    "        for i in range(len(self.class_list)): # for each class, we evaluate its centroid\n",
    "            temp = np.where(y==self.class_list[i])[0]\n",
    "            self.centroids[i,:] = np.mean(X[temp],axis=0)\n",
    "    \n",
    "    def predict(self, X, mtype):\n",
    "        temp = np.argmin(\n",
    "            cdist(X, self.centroids, mtype), # set distance metric\n",
    "            axis=1\n",
    "        )\n",
    "        y_pred = np.array([self.class_list[i] for i in temp])\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return accuracy score of the given dataset with the given metric\n",
    "def mdcScore(datasets,nres,tsize,mtype):\n",
    "    results = {\n",
    "    dataset_name: {\n",
    "        'train' : [None]*nres, \n",
    "        'test'  : [None]*nres\n",
    "    }\n",
    "    for dataset_name in datasets\n",
    "    }\n",
    "    \n",
    "    for dataset_name in datasets:\n",
    "        X = datasets[dataset_name].iloc[:, 0:2].values#data\n",
    "        Y = datasets[dataset_name].iloc[:, 2].values#target\n",
    "\n",
    "        for i in range(nres):\n",
    "            # Train/test split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=tsize)\n",
    "\n",
    "            # scaling\n",
    "            scaler = MinMaxScaler()\n",
    "            X_tr_scaled = scaler.fit_transform(X_train)\n",
    "            X_ts_scaled = scaler.transform(X_test)\n",
    "\n",
    "            # model fitting\n",
    "            mdc = MDC()\n",
    "            mdc.fit(X_tr_scaled, y_train)\n",
    "\n",
    "            # model evaluation\n",
    "            y_pred_tr = mdc.predict(X_tr_scaled, mtype)\n",
    "            y_pred_ts = mdc.predict(X_ts_scaled, mtype)\n",
    "            results[dataset_name]['train'][i] = accuracy_score(y_train, y_pred_tr)*100 # %        \n",
    "            results[dataset_name]['test'][i]  = accuracy_score(y_test,  y_pred_ts)*100 # %\n",
    "\n",
    "        print(dataset_name+\" \"+mtype+\" done\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create accuracy boxplot for MDC\n",
    "def accBox(datasets, results, metric):\n",
    "    switch={\n",
    "        \"euclidean\": 'Euclidean',\n",
    "        \"cityblock\": 'Cityblock',\n",
    "        \"chebyshev\": 'Chessboard'\n",
    "    } \n",
    "    for dataset_name in datasets:\n",
    "        display(HTML('<center><h1>'+dataset_name+' '+switch.get(metric)+'</h1></center>'))\n",
    "\n",
    "        boxs = []\n",
    "        for set_ in ['train', 'test']:\n",
    "            boxs.append(\n",
    "                go.Box(\n",
    "                    y = results[dataset_name][set_],\n",
    "                    x = [\"{}{} set\".format(set_[0].upper(), set_[1:])\n",
    "                        ]*len(results[dataset_name][set_]),\n",
    "                    boxmean='sd', name=set_\n",
    "                    )\n",
    "            )\n",
    "\n",
    "        fig = go.Figure(data   = boxs,\n",
    "                    layout = go.Layout(showlegend=True)\n",
    "                        \n",
    "                   )\n",
    "\n",
    "        fig.update_layout(\n",
    "            margin=dict(l=70, r=70, t=5, b=10),\n",
    "            font=dict(size=15),\n",
    "            yaxis=dict(title='Accuracy (%)'),\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "        display(HTML('<hr>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the plane division for MDC\n",
    "def division(datasets, metric):\n",
    "    switch={\n",
    "        \"euclidean\": 'MDC Euclidean',\n",
    "        \"cityblock\": 'MDC Cityblock',\n",
    "        \"chebyshev\": 'MDC Chessboard'\n",
    "    } \n",
    "    print(switch.get(metric))\n",
    "    for dataset_name in datasets:\n",
    "        X = datasets[dataset_name].iloc[:, 0:2].values#data\n",
    "        Y = datasets[dataset_name].iloc[:, 2].values#target\n",
    "        \n",
    "        # fitting the MDC again\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size)\n",
    "        scaler = MinMaxScaler()\n",
    "        X_tr_scaled = scaler.fit_transform(X_train)\n",
    "        X_ts_scaled = scaler.transform(X_test)\n",
    "\n",
    "        mdc = MDC()\n",
    "        mdc.fit(X_tr_scaled, y_train)\n",
    "\n",
    "\n",
    "        # projecting in 2D space\n",
    "        X_full = np.vstack((X_tr_scaled, X_ts_scaled)) \n",
    "        pca  = PCA(n_components=2)\n",
    "        X_2d = pca.fit_transform(X_full)\n",
    "\n",
    "\n",
    "        # Making graph\n",
    "        fig = go.Figure()\n",
    "\n",
    "        n = 400 # number of points in each dimension\n",
    "        size = 2 # size of points in the coloring grid\n",
    "\n",
    "        x_max, y_max = X_2d.max(0)\n",
    "        x_min, y_min = X_2d.min(0)\n",
    "        x = np.linspace(x_min*1.1, x_max*1.1, n)\n",
    "        y = np.linspace(y_min*1.1, y_max*1.1, n)\n",
    "        # creating the coloring grid data points\n",
    "        xv, yv = np.meshgrid(x, y)\n",
    "        x = xv.flatten()\n",
    "        y = yv.flatten()\n",
    "\n",
    "        grid_pred = mdc.predict(\n",
    "            pca.inverse_transform( np.column_stack((x, y)) ), metric\n",
    "        )\n",
    "\n",
    "        # coloring grid (coloring the regions)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x = x.tolist(),\n",
    "            y = y.tolist(),\n",
    "            mode='markers',\n",
    "            opacity=0.3,\n",
    "            marker = dict( size=size, color= grid_pred )\n",
    "        ))\n",
    "\n",
    "        # data set projection in 2d space\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=X_2d[:,0],\n",
    "            y=X_2d[:,1],\n",
    "            mode='markers',\n",
    "            marker = dict(\n",
    "                size  = 7,\n",
    "                color = np.concatenate([y_train,y_test]),\n",
    "                line  = dict(width=1.5,color='#000000')\n",
    "            )\n",
    "        ))\n",
    "\n",
    "        fig.update_layout(\n",
    "            margin=dict(l=20, r=2, b=0),#t=20),\n",
    "            font=dict(size=20),\n",
    "            autosize=False,\n",
    "            width  = 600,\n",
    "            height = 600,\n",
    "            showlegend = False,\n",
    "            title='{} [{} classes]'.format(dataset_name, len(np.unique(Y)))\n",
    "        )\n",
    "\n",
    "        fig.update_xaxes(range=[x_min*1.1, x_max*1.1]) \n",
    "        fig.update_yaxes(range=[y_min*1.1, y_max*1.1])\n",
    "\n",
    "        fig.show(renderer=\"png\")\n",
    "        display(HTML('<hr>'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return splitted dataframe for KNN\n",
    "def knnPreSplit(df, ts):\n",
    "    #preprocessing\n",
    "    X=df.iloc[:, 0:2].values#data\n",
    "    y=df.iloc[:, 2].values#target\n",
    "    #suddivision\n",
    "    X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=ts)\n",
    "    #feature scaling\n",
    "    scaler=StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train=scaler.transform(X_train)\n",
    "    X_test=scaler.transform(X_test)\n",
    "\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return classifier and predicted targets\n",
    "def knnPred(k,X_train,y_train,X_test):\n",
    "    #training and prediction\n",
    "    classifier=KNeighborsClassifier(k)\n",
    "    classifier.fit(X_train,y_train)\n",
    "\n",
    "    y_pred=classifier.predict(X_test)\n",
    "\n",
    "    return classifier,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print accuracy evaluation\n",
    "def knnEval(y_test,y_pred):\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot KNN plane division\n",
    "def plotKNN(Xtr,Xte,ytr,yte,k,legend,case):\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    padding = 0.1\n",
    "    resolution = 0.1\n",
    "\n",
    "    colors = {0: 'green', 1: 'yellow', 2: 'black'}\n",
    "    x_min, x_max = Xtr[:, 0].min(), Xtr[:, 0].max()\n",
    "    y_min, y_max = Xtr[:, 1].min(), Xtr[:, 1].max()\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    x_min -= x_range * padding\n",
    "    y_min -= y_range * padding\n",
    "    x_max += x_range * padding\n",
    "    y_max += y_range * padding\n",
    "\n",
    "    # Get decision boundaries from model\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, resolution),\n",
    "                         np.arange(y_min, y_max, resolution))\n",
    "\n",
    "    Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot the contour map\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.get_cmap('tab20'))\n",
    "    plt.axis('tight')\n",
    "    \n",
    "    #switch to auto set the name of the graph\n",
    "    switch={\n",
    "        \"general\": 'General K-nearest neighbors case with k= {}'.format(k),\n",
    "        \"low\": 'Worst K-nearest neighbors case with k= {}'.format(k),\n",
    "        \"high\": 'Best K-nearest neighbors case with k= {}'.format(k)\n",
    "    } \n",
    "    \n",
    "    i=0\n",
    "    # Plot your testing points as well\n",
    "    for label in np.unique(yte):\n",
    "        indices = np.where(yte == label)\n",
    "        plt.scatter(Xte[indices, 0], Xte[indices, 1], c=colors[label], alpha=0.8,label=legend[i])\n",
    "        i=i+1\n",
    "    \n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title(switch.get(case))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return array with accuracy for k from 1 to 40 in the test set\n",
    "def varKtest(X_train,y_train,X_test,y_test):#su test\n",
    "    #evaluation varying k\n",
    "    accuracy=[]\n",
    "    #accuracy calculation for k varying from 1 to 40\n",
    "    for i in range(1,41):\n",
    "        k=i\n",
    "        knn=KNeighborsClassifier(n_neighbors=i)\n",
    "        knn.fit(X_train,y_train)\n",
    "        pred_i=knn.predict(X_test)\n",
    "        report = classification_report(y_test, pred_i, output_dict=True)\n",
    "        accuracy.append(report['accuracy'])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return array with accuracy for k from 1 to 40 in the test set\n",
    "def varKtrain(X_train,y_train,X_test,y_test):#su train\n",
    "    #evaluation varying k\n",
    "    accuracy=[]\n",
    "    #accuracy calculation for k varying from 1 to 40\n",
    "    for i in range(1,41):\n",
    "        k=i\n",
    "        knn=KNeighborsClassifier(n_neighbors=i)\n",
    "        knn.fit(X_train,y_train)\n",
    "        pred_i=knn.predict(X_train)\n",
    "        report = classification_report(y_train, pred_i, output_dict=True)\n",
    "        accuracy.append(report['accuracy'])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the accuracy value of each k from 1 to 40\n",
    "def plotVarK(error,name):\n",
    "    #varying k plot\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(range(1,41),error,color='red',linestyle='dashed',marker='o',markerfacecolor='blue',\n",
    "        markersize=10)\n",
    "    plt.title('Accuracy Rate K Value '+name)\n",
    "    plt.xlabel('Kvalue')\n",
    "    plt.ylabel('Accuracy(%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return the values of a good k and a bad k\n",
    "def knnLowHigh(accuracy):\n",
    "    listak=[]\n",
    "    for i in range(1,41):\n",
    "        listak.append(i)\n",
    "    #convert array tinto df   \n",
    "    accuracyDf= pd.DataFrame(accuracy, columns=['accuracy'])\n",
    "    accuracyDf['kappa']=listak\n",
    "    accuracyDf.set_index('kappa', inplace=True)\n",
    "    #sort df\n",
    "    accuracyDf.sort_values(by=['accuracy'], inplace = True)\n",
    "\n",
    "    testa = accuracyDf.head(1)\n",
    "    for row in testa.index:\n",
    "        low=row\n",
    "\n",
    "    coda= accuracyDf.tail(1)\n",
    "    for row in coda.index:\n",
    "        high=row\n",
    "    \n",
    "    print(\"A K with low accuracy: \")\n",
    "    print(low)\n",
    "    print(\"A K with high accuracy: \")\n",
    "    print(high)\n",
    "    return low,high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert accuracy array to dataframe\n",
    "def accuracyDf(accuracy):\n",
    "    listak=[]\n",
    "    for i in range(1,41):\n",
    "        listak.append(i)\n",
    "        \n",
    "    a= pd.DataFrame(accuracy, columns=['accuracy'])\n",
    "    a['kappa']=listak\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print two accuracy boxplot, one for the train set and one for the test set of the KNN\n",
    "def BoxCompare(Test_set, Train_set, ds_arg):\n",
    "\n",
    "    if ds_arg==\"Iris\":\n",
    "        tit=\"Boxplot KNN Iris\"\n",
    "    else:\n",
    "        tit=\"Boxplot KNN Wine\"\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Box(y=Train_set[\"accuracy\"], name=\"Train set\"))\n",
    "    fig.add_trace(go.Box(y=Test_set[\"accuracy\"], name=\"Test set\"))\n",
    "    fig.update_layout(title=tit ,yaxis_title=\"Accuracy\",xaxis_title=\"Test\")\n",
    "    \n",
    "    fig.show()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
